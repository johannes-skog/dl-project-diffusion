{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e89f0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))\n",
    "\n",
    "import sys\n",
    "import os \n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from einops import rearrange\n",
    "import einops \n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from datasets import load_dataset\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from typing import List\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4cce9f",
   "metadata": {},
   "source": [
    "# Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3009edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset wikitext/wikitext-103-raw-v1 to /home/johannes/.cache/huggingface/datasets/wikitext/wikitext-103-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467c0eec734d423382806a637f8fc333",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/192M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/4358 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/1801350 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3760 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset wikitext downloaded and prepared to /home/johannes/.cache/huggingface/datasets/wikitext/wikitext-103-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0cba4d0b4a4d8fba20306bbaeee954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\")\n",
    "dataset_train = dataset[\"train\"].map(lambda e: tokenizer(e['text'], truncation=True, padding='max_length'), batched=True)\n",
    "dataset_train.set_format(type='torch', columns=['input_ids', 'text', 'attention_mask'])\n",
    "dataset_train.save_to_disk(\"datasets/wikitext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83a701cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikipedia (/home/johannes/.cache/huggingface/datasets/wikipedia/20220301.en/2.0.0/aa542ed919df55cc5d3347f42dd4521d05ca68751f50dbc32bae2a7f1e167559)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24db49f6e1cb4de88dfae51d59a43b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"wikipedia\", \"20220301.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de4f80c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a8448b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f197ee45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80a021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35038aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "bba5f30b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset wikitext (/home/johannes/.cache/huggingface/datasets/wikitext/wikitext-103-raw-v1/1.0.0/a241db52902eaf2c6aa732210bead40c090019a499ceb13bcbfa3f8ab646a126)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "312cbab37cc5483ea6294b4094ff9059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d930b746c29244e9bec610326888213e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1802 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-103-raw-v1\")\n",
    "dataset_train = dataset[\"train\"].map(lambda e: tokenizer(e['text'], truncation=True, padding='max_length'), batched=True)\n",
    "dataset_train.set_format(type='torch', columns=['input_ids', 'text', 'attention_mask'])\n",
    "dataset_train.save_to_disk(\"datasets/wikitext_xlmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30113460",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_from_disk\n",
    "reloaded_dataset = load_from_disk(\"datasets/wikitext_xlmr\")\n",
    "dataloader = torch.utils.data.DataLoader(reloaded_dataset, batch_size=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7170d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0b8f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for batch in dataloader:\n",
    "    \n",
    "    i +=1\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7441c35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86db967",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04866930",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243fc114",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645c075",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer([text, text], return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68b5e3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "82e32e27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08eafa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "aefcbda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_model import TransformerModel\n",
    "\n",
    "decoder = torch.nn.Sequential(\n",
    "    xlmr_model.lm_head\n",
    ")\n",
    "\n",
    "transformer_model = TransformerModel(\n",
    "    nlayers=8,\n",
    "    decoder=decoder,\n",
    "    timesteps=TIMESTEPS,\n",
    "    hidden_dim=1024,\n",
    "    max_seq_len=512,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa9d63",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9a9518",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9309031c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "input_ids = batch[\"input_ids\"].to(device)\n",
    "attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    xlmr_model.eval()\n",
    "\n",
    "    output = xlmr_model.forward(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        output_hidden_states=True,\n",
    "    ).hidden_states[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "919efcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    xt, noise, t = diffusion_linear.forward(output)\n",
    "\n",
    "    # add noise, Analyze the distribution for the hidden state\n",
    "    y, y_decoded = transformer_model(xt, attention_mask=attention_mask, t=t)\n",
    "    \n",
    "    pos = transformer_model._pos_encoder(output)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a930d27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f10068c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "yt = transformer_model._time_embedder(t).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c89a7825",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = yt + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "41977d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "cc = cc - yt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74c04772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0732e-10, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(cc - y).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9c6b241c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ba6148c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "76264249",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion import Diffusion\n",
    "\n",
    "diffusion_linear = Diffusion(\n",
    "    timesteps=TIMESTEPS,\n",
    "    schedular=\"linear\",\n",
    "    start=0.0001,\n",
    "    end=0.002\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6acff9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86c19b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.011213302612304688"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = batch[\"input_ids\"].to(device)\n",
    "attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "xlmr_model.eval()\n",
    "\n",
    "import time \n",
    "\n",
    "s = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    output = xlmr_model.forward(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        output_hidden_states=True,\n",
    "    )\n",
    "\n",
    "    output_hidden = output.hidden_states[-1]\n",
    "\n",
    "e = time.time()\n",
    "  \n",
    "e - s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b9243cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 500\n",
    "\n",
    "with torch.no_grad():\n",
    "    decoder.eval()\n",
    "    xt, noise, t = diffusion_linear.forward(output_hidden, torch.Tensor([t] * output_hidden.shape[0]).long().to(device))\n",
    "    \n",
    "    output_decoded = decoder(xt)\n",
    "    \n",
    "    y = transformer_model(xt, attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a219c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion import Diffusion\n",
    "\n",
    "def process_backward(\n",
    "    model: torch.nn.Module,\n",
    "    diffusion: Diffusion,\n",
    "    timesteps: int,\n",
    "    shape: List[int],\n",
    "    device: str,\n",
    "    x: torch.Tensor = None,\n",
    "):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        x = torch.randn(shape, device=device) if x is None else x\n",
    "        timesteps_iter = list(range(timesteps))\n",
    "        timesteps_iter.reverse()\n",
    "        \n",
    "        attention_mask = torch.ones([1, MAX_SEQUENCE_LENGTH]).to(device)\n",
    "        \n",
    "        Y = [x]\n",
    "        \n",
    "        for t in timesteps_iter:\n",
    "\n",
    "            t = torch.Tensor([t]).long().to(device)\n",
    "\n",
    "            predicted_noise, _ = model.forward(\n",
    "                x=x,\n",
    "                t=t,\n",
    "                attention_mask=attention_mask,\n",
    "            #    klass\n",
    "            )\n",
    "            \n",
    "            if torch.isnan(predicted_noise).sum() > 0:\n",
    "                print(t)\n",
    "            \n",
    "            x = diffusion.backward(x, predicted_noise, t)\n",
    "            \n",
    "            Y.append(x)\n",
    "            \n",
    "        return torch.cat(Y, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32b5518f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "TIMESTEPS = 300\n",
    "MAX_SEQUENCE_LENGTH = 512\n",
    "HIDDEN_DIM = 1024\n",
    "BATCH_SIZE = 5\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-large')\n",
    "xlmr_model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-large\").to(device)\n",
    "\n",
    "from datasets import load_from_disk\n",
    "reloaded_dataset = load_from_disk(\"datasets/wikitext_xlmr\")\n",
    "dataloader = torch.utils.data.DataLoader(reloaded_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "from transformer_model import TransformerModel\n",
    "\n",
    "decoder = torch.nn.Sequential(\n",
    "    xlmr_model.lm_head\n",
    ")\n",
    "\n",
    "transformer_model = TransformerModel(\n",
    "    nlayers=8,\n",
    "    decoder=None,\n",
    "    timesteps=TIMESTEPS,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    max_seq_len=MAX_SEQUENCE_LENGTH,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10ae98cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from diffusion import Diffusion\n",
    "\n",
    "diffusion_linear = Diffusion(\n",
    "    timesteps=TIMESTEPS,\n",
    "    schedular=\"linear\",\n",
    "    start=0.0001,\n",
    "    end=0.002\n",
    ")\n",
    "\n",
    "model = transformer_model\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "iteration = 0\n",
    "image_saves = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a317cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    output_hidden = xlmr_model.forward(\n",
    "        input_ids=input_ids,\n",
    "        attention_mask=attention_mask,\n",
    "        output_hidden_states=True,\n",
    "    ).hidden_states[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6925bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "iteration = 299"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce22f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = \"test_transformers\"\n",
    "\n",
    "writer = SummaryWriter(f\"runs/{EXPERIMENT_NAME}\")\n",
    "\n",
    "for e in range(1):\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        \n",
    "        iteration += 1\n",
    "        \n",
    "        model.train()\n",
    "        xlmr_model.eval()\n",
    "        decoder.eval()\n",
    "\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            output_hidden = xlmr_model.forward(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask,\n",
    "                output_hidden_states=True,\n",
    "            ).hidden_states[-1]\n",
    "\n",
    "            x_noised, noise, time = diffusion_linear.forward(output_hidden)\n",
    "        \n",
    "        noise_predicted, _ = model.forward(\n",
    "            x=x_noised,\n",
    "            t=time,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        loss = diffusion_linear.loss(noise, noise_predicted)\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # torch.nn.utils.clip_grad_norm(parameters=model.parameters(), max_norm=2, norm_type=2)\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar(\"loss\", loss, iteration)\n",
    "        \n",
    "        if iteration % 300 == 0:\n",
    "            \n",
    "            with torch.no_grad():\n",
    "\n",
    "                y_final = process_backward(\n",
    "                    model=model,\n",
    "                    diffusion=diffusion_linear,\n",
    "                    timesteps=TIMESTEPS,\n",
    "                    shape=[1, MAX_SEQUENCE_LENGTH, HIDDEN_DIM],\n",
    "                    device=device,\n",
    "                )[-1, :, :]\n",
    "\n",
    "                decoder.eval()\n",
    "                output_decoded = decoder(y_final)\n",
    "\n",
    "                output_max = list(output_decoded.argmax(1).detach().cpu().numpy())\n",
    "\n",
    "                text = tokenizer.decode(output_max)\n",
    "\n",
    "                writer.add_text(\"model_output\", text, global_step=image_saves)\n",
    "\n",
    "            image_saves += 1\n",
    "            \n",
    "            model.save(folder=f\"ckp/{EXPERIMENT_NAME}\", name=\"best.ckp\")\n",
    "\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4b909c6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([370, 638, 503, 956, 946], device='cuda:0')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67cb03d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "087ebf1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 512, 1024])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9447e5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    \n",
    "    y_final = process_backward(\n",
    "        model=model,\n",
    "        diffusion=diffusion_linear,\n",
    "        timesteps=TIMESTEPS,\n",
    "        shape=[1, MAX_SEQUENCE_LENGTH, HIDDEN_DIM],\n",
    "        device=device,\n",
    "    )[-1, :, :]\n",
    "\n",
    "    decoder.eval()\n",
    "    output_decoded = model._decoder(y_final)\n",
    "    \n",
    "    output_max = list(output_decoded.argmax(1).detach().cpu().numpy())\n",
    "\n",
    "    text = tokenizer.decode(output_max)\n",
    "    \n",
    "    writer.add_text(\"first_text\", text, global_step=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71566c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63f0c5a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "300e25b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
