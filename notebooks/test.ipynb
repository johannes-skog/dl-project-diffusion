{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e89f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os \n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from einops import rearrange\n",
    "import einops \n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "100ac1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.random.uniform(size=[32, 8, 128, 10])\n",
    "k = np.random.uniform(size=[32, 8, 128, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e205e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec6746c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim2 = np.einsum(\"bhdi, bhdj -> bhdji\", q, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616a5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aee1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a701cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/home/johannes/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a8e53ff7e44a5ab8eef3f4eb60c633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"fashion_mnist\")\n",
    "IMAGE_SIZE = 28\n",
    "CHANNELS = 1\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eec868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import Unet\n",
    "from diffusion import Diffusion\n",
    "\n",
    "unet = Unet(\n",
    "    scale_channels=32,\n",
    "    init_channels=128,\n",
    "    out_channels=1,\n",
    "    nchannels=CHANNELS,\n",
    ")\n",
    "\n",
    "diffusion = Diffusion(\n",
    "    timesteps=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "941aaf8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [   transforms.Resize(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def normalize(examples):\n",
    "    \n",
    "    examples[\"x\"] = [transform(image.convert(\"L\")) for image in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "\n",
    "    return examples\n",
    "\n",
    "transformed_dataset = dataset.with_transform(normalize)\n",
    "\n",
    "# create dataloader\n",
    "dataloader = DataLoader(transformed_dataset[\"train\"], batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab072524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db77033c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "\n",
    "reverse_transform = transforms.Compose([\n",
    "     transforms.Lambda(lambda t: t[0, :, :, :]),\n",
    "     transforms.Resize(128),\n",
    "     transforms.Lambda(lambda t: (t + 1) / 2),\n",
    "     transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "     transforms.Lambda(lambda t: t * 255.),\n",
    "     transforms.Lambda(lambda t: t.to(\"cpu\"),),\n",
    "     transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "     transforms.ToPILImage(),\n",
    "])\n",
    "\n",
    "def _generate_image(\n",
    "    model: torch.nn.Module,\n",
    "    diffusion: Diffusion,\n",
    "    timesteps: int,\n",
    "    shape: List[int],\n",
    "    device: str,\n",
    "):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        x = torch.randn(shape, device=device)\n",
    "\n",
    "        timesteps_iter = list(range(timesteps))\n",
    "        timesteps_iter.reverse()\n",
    "\n",
    "        for t in timesteps_iter:\n",
    "\n",
    "            t = torch.Tensor([t]).long().to(device)\n",
    "\n",
    "            predicted_noise = model.forward(x, t)\n",
    "\n",
    "            x = diffusion.backward(x, predicted_noise, t)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa032d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = _generate_image(\n",
    "    model=unet,\n",
    "    diffusion=diffusion,\n",
    "    timesteps=200,\n",
    "    shape=[1, 1, 32, 32],\n",
    "    device=device,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e6fb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "de5620a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5135f3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     unet\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     31\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 32\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_scalar(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, loss, iteration)\n\u001b[1;32m     36\u001b[0m y \u001b[38;5;241m=\u001b[39m _generate_image(\n\u001b[1;32m     37\u001b[0m     model\u001b[38;5;241m=\u001b[39munet,\n\u001b[1;32m     38\u001b[0m     diffusion\u001b[38;5;241m=\u001b[39mdiffusion,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     41\u001b[0m     device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     42\u001b[0m )\n",
      "File \u001b[0;32m~/own/dl-projects/dl-project-diffusion/.env/lib/python3.9/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/own/dl-projects/dl-project-diffusion/.env/lib/python3.9/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/own/dl-projects/dl-project-diffusion/.env/lib/python3.9/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/own/dl-projects/dl-project-diffusion/.env/lib/python3.9/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/own/dl-projects/dl-project-diffusion/.env/lib/python3.9/site-packages/torch/optim/adam.py:263\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    262\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 263\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable:\n\u001b[1;32m    266\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "writer = SummaryWriter(\"runs/test1\")\n",
    "writer.add_scalar(\"hejsan\", 5, 9)\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "unet.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=1e-3)\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for e in range(100):\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        x = batch[\"x\"].to(device)\n",
    "\n",
    "        x_noised, noise, time = diffusion.forward(x)\n",
    "\n",
    "        noise_predicted = unet.forward(x_noised.to(device), time.to(device))\n",
    "\n",
    "        loss = diffusion.loss(noise, noise_predicted)\n",
    "        \n",
    "        unet.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar(\"loss\", loss, iteration)\n",
    "    \n",
    "    print(e)\n",
    "    \n",
    "    y = _generate_image(\n",
    "        model=unet,\n",
    "        diffusion=diffusion,\n",
    "        timesteps=200,\n",
    "        shape=[1, 1, 32, 32],\n",
    "        device=device,\n",
    "    )\n",
    "        \n",
    "    writer.add_image(f'epoch_{e}',np.expand_dims(np.asarray(reverse_transform(y)), 2), 0, dataformats='HWC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bacf56",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "26c623f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = unet(batch[\"x\"], time=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5933f6b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a8eae96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2c58c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = reverse_transform(y[0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c604553",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34e249dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47679a5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea3a698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e792b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b242d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db285a91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
