{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e89f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os \n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "from einops import rearrange\n",
    "import einops \n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "100ac1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.random.uniform(size=[32, 8, 128, 10])\n",
    "k = np.random.uniform(size=[32, 8, 128, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e205e7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec6746c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim2 = np.einsum(\"bhdi, bhdj -> bhdji\", q, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616a5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aee1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "83a701cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset mnist (/home/johannes/.cache/huggingface/datasets/mnist/mnist/1.0.0/fda16c03c4ecfb13f165ba7e29cf38129ce035011519968cdaf74894ce91c9d4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fbd1faa52ea4896bea8e0ee3a16ffba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"mnist\")\n",
    "IMAGE_SIZE = 28\n",
    "CHANNELS = 1\n",
    "BATCH_SIZE = 64\n",
    "TIMESTEPS = 300\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1eec868e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "functools.partial(<class 'utils.ResnetBlock'>, norm_groups=8)\n"
     ]
    }
   ],
   "source": [
    "from unet import Unet\n",
    "from diffusion import Diffusion\n",
    "\n",
    "unet = Unet(\n",
    "    channels=[32, 64, 128, 256],\n",
    "    in_channels=1,\n",
    "    resnet_block_groups=8,\n",
    "    use_convnext=False,\n",
    "    convnext_mult=2,\n",
    "    init_channel_mult=32,\n",
    ")\n",
    "\n",
    "diffusion = Diffusion(\n",
    "    timesteps=TIMESTEPS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "678c4197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [   \n",
    "        transforms.Resize(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def normalize(examples):\n",
    "    \n",
    "    examples[\"x\"] = [transform(image.convert(\"L\")) for image in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "\n",
    "    return examples\n",
    "\n",
    "transformed_dataset = dataset.with_transform(normalize)\n",
    "\n",
    "# create dataloader\n",
    "dataloader = DataLoader(transformed_dataset[\"train\"], batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1065dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14760980",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "72c242f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "\n",
    "reverse_transform = transforms.Compose([\n",
    "     # transforms.Lambda(lambda t: t[0, :, :, :]),\n",
    "     transforms.Resize(128),\n",
    "     transforms.Lambda(lambda t: (t + 1) / 2),\n",
    "     transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "     transforms.Lambda(lambda t: t * 255.),\n",
    "     transforms.Lambda(lambda t: t.to(\"cpu\"),),\n",
    "     transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "     transforms.ToPILImage(),\n",
    "])\n",
    "\n",
    "reverse_transform2 = transforms.Compose([\n",
    "     # transforms.Lambda(lambda t: t[0, :, :, :]),\n",
    "     transforms.Resize(128),\n",
    "     transforms.Lambda(lambda t: (t + 1) / 2),\n",
    "     # transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
    "     transforms.Lambda(lambda t: t * 255.),\n",
    "     transforms.Lambda(lambda t: t.to(\"cpu\"),),\n",
    "     # transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
    "     # transforms.ToPILImage(),\n",
    "])\n",
    "\n",
    "\n",
    "def _generate_image(\n",
    "    model: torch.nn.Module,\n",
    "    diffusion: Diffusion,\n",
    "    timesteps: int,\n",
    "    shape: List[int],\n",
    "    device: str,\n",
    "):\n",
    "    with torch.no_grad():\n",
    "\n",
    "        x = torch.randn(shape, device=device)\n",
    "\n",
    "        timesteps_iter = list(range(timesteps))\n",
    "        timesteps_iter.reverse()\n",
    "        \n",
    "        Y = [x]\n",
    "        \n",
    "        for t in timesteps_iter:\n",
    "\n",
    "            t = torch.Tensor([t]).long().to(device)\n",
    "\n",
    "            predicted_noise = model.forward(x, t)\n",
    "\n",
    "            x = diffusion.backward(x, predicted_noise, t)\n",
    "\n",
    "            Y.append(x)\n",
    "            \n",
    "        return torch.cat(Y, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "567fcddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = _generate_image(\n",
    "    model=unet,\n",
    "    diffusion=diffusion,\n",
    "    timesteps=TIMESTEPS,\n",
    "    shape=[1, 1, 32, 32],\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7173d115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([201, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a013a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = reverse_transform(y[-1, :, :, :])\n",
    "\n",
    "image.save(\"tmp.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2c2e9a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1ad21da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77a26845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for step, batch in enumerate(dataloader):\n",
    "\n",
    "    x = batch[\"x\"].to(device)\n",
    "    \n",
    "    break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7e300afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unet(\n",
       "  (_init_conv): Conv2d(1, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
       "  (time_mlp): Sequential(\n",
       "    (0): SinusoidalPositionEmbeddings()\n",
       "    (1): Linear(in_features=32, out_features=128, bias=True)\n",
       "    (2): GELU(approximate=none)\n",
       "    (3): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (_down_sampling_layers): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): ConvNextBlock(\n",
       "        (_time_embedder): Sequential(\n",
       "          (0): GELU(approximate=none)\n",
       "          (1): Linear(in_features=128, out_features=32, bias=True)\n",
       "        )\n",
       "        (_dw_conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\n",
       "        (_convs): Sequential(\n",
       "          (0): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (_res_conv): Identity()\n",
       "      )\n",
       "      (1): ConvNextBlock(\n",
       "        (_time_embedder): Sequential(\n",
       "          (0): GELU(approximate=none)\n",
       "          (1): Linear(in_features=128, out_features=32, bias=True)\n",
       "        )\n",
       "        (_dw_conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\n",
       "        (_convs): Sequential(\n",
       "          (0): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (_res_conv): Identity()\n",
       "      )\n",
       "      (2): Residual(\n",
       "        (_func): GroupPreNormalizer(\n",
       "          (_func): ConvLinearAttention(\n",
       "            (_qkv_net): Conv2d(32, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (_out_net): Sequential(\n",
       "              (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "            )\n",
       "          )\n",
       "          (_normalizer): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Conv2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): ConvNextBlock(\n",
       "        (_time_embedder): Sequential(\n",
       "          (0): GELU(approximate=none)\n",
       "          (1): Linear(in_features=128, out_features=32, bias=True)\n",
       "        )\n",
       "        (_dw_conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\n",
       "        (_convs): Sequential(\n",
       "          (0): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (1): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (_res_conv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvNextBlock(\n",
       "        (_time_embedder): Sequential(\n",
       "          (0): GELU(approximate=none)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (_dw_conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
       "        (_convs): Sequential(\n",
       "          (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (_res_conv): Identity()\n",
       "      )\n",
       "      (2): Residual(\n",
       "        (_func): GroupPreNormalizer(\n",
       "          (_func): ConvLinearAttention(\n",
       "            (_qkv_net): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (_out_net): Sequential(\n",
       "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "            )\n",
       "          )\n",
       "          (_normalizer): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (2): ModuleList(\n",
       "      (0): ConvNextBlock(\n",
       "        (_time_embedder): Sequential(\n",
       "          (0): GELU(approximate=none)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (_dw_conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
       "        (_convs): Sequential(\n",
       "          (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (1): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (_res_conv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvNextBlock(\n",
       "        (_time_embedder): Sequential(\n",
       "          (0): GELU(approximate=none)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (_dw_conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "        (_convs): Sequential(\n",
       "          (0): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (_res_conv): Identity()\n",
       "      )\n",
       "      (2): Residual(\n",
       "        (_func): GroupPreNormalizer(\n",
       "          (_func): ConvLinearAttention(\n",
       "            (_qkv_net): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (_out_net): Sequential(\n",
       "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "            )\n",
       "          )\n",
       "          (_normalizer): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): Identity()\n",
       "    )\n",
       "  )\n",
       "  (_up_sampling_layers): ModuleList(\n",
       "    (0): ModuleList(\n",
       "      (0): ConvNextBlock(\n",
       "        (_time_embedder): Sequential(\n",
       "          (0): GELU(approximate=none)\n",
       "          (1): Linear(in_features=128, out_features=256, bias=True)\n",
       "        )\n",
       "        (_dw_conv): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "        (_convs): Sequential(\n",
       "          (0): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "          (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (_res_conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvNextBlock(\n",
       "        (_time_embedder): Sequential(\n",
       "          (0): GELU(approximate=none)\n",
       "          (1): Linear(in_features=128, out_features=64, bias=True)\n",
       "        )\n",
       "        (_dw_conv): Conv2d(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=64)\n",
       "        (_convs): Sequential(\n",
       "          (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (4): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (_res_conv): Identity()\n",
       "      )\n",
       "      (2): Residual(\n",
       "        (_func): GroupPreNormalizer(\n",
       "          (_func): ConvLinearAttention(\n",
       "            (_qkv_net): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (_out_net): Sequential(\n",
       "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "            )\n",
       "          )\n",
       "          (_normalizer): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "    (1): ModuleList(\n",
       "      (0): ConvNextBlock(\n",
       "        (_time_embedder): Sequential(\n",
       "          (0): GELU(approximate=none)\n",
       "          (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (_dw_conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "        (_convs): Sequential(\n",
       "          (0): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "          (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (_res_conv): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (1): ConvNextBlock(\n",
       "        (_time_embedder): Sequential(\n",
       "          (0): GELU(approximate=none)\n",
       "          (1): Linear(in_features=128, out_features=32, bias=True)\n",
       "        )\n",
       "        (_dw_conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\n",
       "        (_convs): Sequential(\n",
       "          (0): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (2): GELU(approximate=none)\n",
       "          (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "          (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        )\n",
       "        (_res_conv): Identity()\n",
       "      )\n",
       "      (2): Residual(\n",
       "        (_func): GroupPreNormalizer(\n",
       "          (_func): ConvLinearAttention(\n",
       "            (_qkv_net): Conv2d(32, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (_out_net): Sequential(\n",
       "              (0): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "              (1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "            )\n",
       "          )\n",
       "          (_normalizer): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "        )\n",
       "      )\n",
       "      (3): ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (mid_block1): ConvNextBlock(\n",
       "    (_time_embedder): Sequential(\n",
       "      (0): GELU(approximate=none)\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (_dw_conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "    (_convs): Sequential(\n",
       "      (0): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): GELU(approximate=none)\n",
       "      (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "      (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (_res_conv): Identity()\n",
       "  )\n",
       "  (mid_attn): Residual(\n",
       "    (_func): GroupPreNormalizer(\n",
       "      (_func): ConvAttention(\n",
       "        (_qkv_net): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (_out_net): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (_normalizer): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (mid_block2): ConvNextBlock(\n",
       "    (_time_embedder): Sequential(\n",
       "      (0): GELU(approximate=none)\n",
       "      (1): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (_dw_conv): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "    (_convs): Sequential(\n",
       "      (0): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      (1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (2): GELU(approximate=none)\n",
       "      (3): GroupNorm(1, 256, eps=1e-05, affine=True)\n",
       "      (4): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    )\n",
       "    (_res_conv): Identity()\n",
       "  )\n",
       "  (final_conv): Sequential(\n",
       "    (0): ConvNextBlock(\n",
       "      (_dw_conv): Conv2d(32, 32, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=32)\n",
       "      (_convs): Sequential(\n",
       "        (0): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "        (1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (2): GELU(approximate=none)\n",
       "        (3): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "        (4): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      )\n",
       "      (_res_conv): Identity()\n",
       "    )\n",
       "    (1): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "unet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "c730f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_noised, noise, time = diffusion.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1c367faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h torch.Size([1, 128, 7, 7])\n",
      "torch.Size([1, 256, 7, 7])\n",
      "before up last torch.Size([1, 64, 7, 7])\n",
      "ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "hejsans\n",
      "h torch.Size([1, 64, 14, 14])\n",
      "torch.Size([1, 128, 14, 14])\n",
      "before up last torch.Size([1, 32, 14, 14])\n",
      "ConvTranspose2d(32, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "hejsans\n",
      "last22222222 torch.Size([1, 32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "noise_predicted = unet.forward(x_noised.to(device), time.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3a0a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "writer = SummaryWriter(\"runs/test2\")\n",
    "writer.add_scalar(\"hejsan\", 5, 9)\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "unet.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=1e-3)\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for e in range(500):\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        x = batch[\"x\"].to(device)\n",
    "\n",
    "        x_noised, noise, time = diffusion.forward(x)\n",
    "\n",
    "        noise_predicted = unet.forward(x_noised.to(device), time.to(device))\n",
    "\n",
    "        loss = diffusion.loss(noise, noise_predicted)\n",
    "        \n",
    "        unet.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        writer.add_scalar(\"loss\", loss, iteration)\n",
    "    \n",
    "    print(e)\n",
    "    \n",
    "    y = _generate_image(\n",
    "        model=unet,\n",
    "        diffusion=diffusion,\n",
    "        timesteps=TIMESTEPS,\n",
    "        shape=[1, 1, 32, 32],\n",
    "        device=device,\n",
    "    )\n",
    "        \n",
    "    writer.add_image(f'images',np.expand_dims(np.asarray(reverse_transform(y[-1, :, :, :])), 2), e, dataformats='HWC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe3e773",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f73ce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = unet(batch[\"x\"], time=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4af68ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4fef58e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c3ce3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = reverse_transform(y[0, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4220a675",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from matplotlib import cm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1a5ba6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d34a3c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0741eec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7747d2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ff5419",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f49e7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
