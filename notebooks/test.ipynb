{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e89f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os \n",
    "\n",
    "os.chdir(\"../\")\n",
    "\n",
    "# sys.path.append(\"../\")\n",
    "\n",
    "from einops import rearrange\n",
    "import einops \n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "100ac1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = np.random.uniform(size=[32, 8, 128, 10])\n",
    "k = np.random.uniform(size=[32, 8, 128, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e205e7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The last argument passed to `einops.einsum` must be a string, representing the einsum pattern.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [29]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sim \u001b[38;5;241m=\u001b[39m \u001b[43meinops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meinsum\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbhdi, bhdj -> bhij\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/einops/einops.py:779\u001b[0m, in \u001b[0;36meinsum\u001b[0;34m(*tensors_and_pattern)\u001b[0m\n\u001b[1;32m    777\u001b[0m pattern \u001b[38;5;241m=\u001b[39m tensors_and_pattern[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    778\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pattern, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 779\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    780\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe last argument passed to `einops.einsum` must be a string,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    781\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m representing the einsum pattern.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    782\u001b[0m     )\n\u001b[1;32m    783\u001b[0m tensors \u001b[38;5;241m=\u001b[39m tensors_and_pattern[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    784\u001b[0m pattern \u001b[38;5;241m=\u001b[39m _compactify_pattern_for_einsum(pattern)\n",
      "\u001b[0;31mValueError\u001b[0m: The last argument passed to `einops.einsum` must be a string, representing the einsum pattern."
     ]
    }
   ],
   "source": [
    "sim = einops.einsum(\"bhdi, bhdj -> bhij\", q, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec6746c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim2 = np.einsum(\"bhdi, bhdj -> bhdji\", q, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b616a5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aee1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83a701cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset fashion_mnist (/home/johannes/.cache/huggingface/datasets/fashion_mnist/fashion_mnist/1.0.0/8d6c32399aa01613d96e2cbc9b13638f359ef62bb33612b077b4c247f6ef99c1)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "770166252df94c4984da9b4e2d99ec0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"fashion_mnist\")\n",
    "IMAGE_SIZE = 28\n",
    "CHANNELS = 1\n",
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1eec868e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unet import Unet\n",
    "from diffusion import Diffusion\n",
    "\n",
    "unet = Unet(\n",
    "    scale_channels=32,\n",
    "    init_channels=128,\n",
    "    out_channels=1,\n",
    "    nchannels=CHANNELS,\n",
    ")\n",
    "\n",
    "diffusion = Diffusion(\n",
    "    timesteps=200,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45a6117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [   transforms.Resize(32),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda t: (t * 2) - 1)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def normalize(examples):\n",
    "    \n",
    "    examples[\"x\"] = [transform(image.convert(\"L\")) for image in examples[\"image\"]]\n",
    "    del examples[\"image\"]\n",
    "\n",
    "    return examples\n",
    "\n",
    "transformed_dataset = dataset.with_transform(normalize)\n",
    "\n",
    "# create dataloader\n",
    "dataloader = DataLoader(transformed_dataset[\"train\"], batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369d567",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f1ed707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Writer will output to ./runs/ directory by default\n",
    "writer = SummaryWriter(\"runs/test1\")\n",
    "writer.add_scalar(\"hejsan\", 5, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521e41db",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "unet.to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(unet.parameters(), lr=1e-3)\n",
    "\n",
    "iteration = 0\n",
    "\n",
    "for e in range(100):\n",
    "\n",
    "    for step, batch in enumerate(dataloader):\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        x = batch[\"x\"].to(device)\n",
    "\n",
    "        x_noised, noise, time = diffusion.forward(x)\n",
    "\n",
    "        noise_predicted = unet.forward(x_noised.to(device), time.to(device))\n",
    "\n",
    "        loss = diffusion.loss(noise, noise_predicted)\n",
    "\n",
    "        writer.add_scalar(\"loss\", loss, iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "889afc5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4943, device='cuda:0', grad_fn=<SmoothL1LossBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfdbdaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = unet(batch[\"x\"], time=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3a46b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdea00cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "801d9515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536497a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e5a84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcdcd32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f873db3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df99ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5276b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740488ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
